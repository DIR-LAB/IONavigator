# Optimizing HPC I/O Performance with Regression Analysis and Ensemble Learning

Zhangyu Liu† ∗, Cheng Zhang† ∗, Huijun Wu‡, Jianbin Fang‡, Lin Peng‡, Guixin Ye†, Zhanyong Tang† §

†School of Information Science & Technology, Northwest University, Xi'an, China

‡College of Computer, National University of Defense Technology, Changsha, China

Email: liuzhangyu@stumail.nwu.edu.cn zytang@nwu.edu.cn

*Abstract*—To improve parallel I/O performance, it is imperative to optimize the adjustable parameters across the different layers of the I/O software stack. Finding an optimal configuration for different scenarios is hampered by the complex interaction dynamics between these parameters and the large parameter space. Previous research efforts have focused on tuning these parameters using independent algorithms; however, these approaches exhibit certain shortcomings such as unstable performance results and delayed convergence rates.

This paper introduces OPRAEL, an auto-tuning approach on parallel I/O tasks by ensembles and performance modeling using regression analysis. To test its effectiveness, we applied this approach on the Tianhe-II supercomputer using one well-known I/O benchmark(IOR) and two I/O kernels(S3D-I/O, BT-I/O). Leveraging our experience in predictive modeling, we optimized the tuning of the I/O stack parameters. Our experimental results show a remarkable 10.2X improvement in write performance speedup for the optimization task with BT-I/O and a 500x500x500 input. We also compared the potential of using a single search algorithm versus using reinforcement learning search in the I/O parameter auto-optimization task. Our results show that OPRAEL outperforms the traditional approach, resulting in a maximum 8.4X improvement in write performance for the 128 process IOR optimization.

*Index Terms*—HPC, Parallel I/O, Performance Optimization, Auto-tuning, Ensemble Learning

## I. INTRODUCTION

As more scientific I/O applications are developed and used on high-performance computing (HPC) systems, up to millions of parallel processing workers run simultaneously, processing and generating up to several petabytes of data [1]. However, as the gap between compute power and I/O systems continues to widen, and the shared nature of I/O subsystems, I/O has become a major performance bottleneck limiting the HPC systems [2]–[5]. Thus, optimizing the I/O processing is among the most needed parts [6]. Due to the complexity of large-scale supercomputers and the limited human's understandings, it is challenging to improve I/O performance, and an urgent need to find a light-weight and efficient way to achieve such a goal.

Various software and hardware components are involved in performing the parallel I/O operations. A typical I/O stack consists of high-level I/O libraries (e.g., HDF5 [7], ADIOSciteM15, and PnetCDF [8]), I/O middleware (e.g., MPI-IO [9]), parallel file systems (e.g., Lustre and GPFS), and the underlying storage hardware. Each of these layers provides tunable parameters [10] [11], deciding how to move data between intermediate nodes and how to store data on disk, to meet different requirements of individual workloads [12]. However, selecting a set of well-performing parameters for HPC applications is difficult due to complex interactions between multiple layers of parallel I/O stack. Domain scientists usually resort to default storage system configurations [12] [13] [14], which generally lead to poor I/O performance. Choosing a good set of configurations becomes the key to improving I/O performance.

Selecting a set of well-performing parameters is challenging due to various parameters and their large number of discrete options. Previous works often use algorithms or models to automatically find better-performing configurations in a given parameter space, including genetic algorithms (GA) [6], [12], Bayesian Optimization [15], [16], and reinforcement learning [17], [18]. These methods work independently to find the optimal configuration by their searching strategies in limited rounds or time. These works are either applicable to only limited applications and input workloads [10], or behave unstably, which is unacceptable in a production environment [19].

This paper introduces a novel auto-tuning framework that relies on ensemble learning. By leveraging the collective knowledge gained from diverse algorithms, the proposed approach enhances the stability and performance of the results by utilizing superior solutions generated by other algorithms to guide the search process. The framework is composed of three algorithms, namely Genetic Algorithm, TPE, and Bayesian Optimization, where each algorithm generates a set of configurations. The performance of these configurations is subsequently evaluated using a prediction model. The optimal configuration for the current round is then selected through a voting mechanism, with the process repeating until either a time period or iteration limit is reached. To demonstrate the efficacy of our approach, a system named OPRAEL1 has been built based on the proposed framework.

Our paper makes the following contributions.

- We are the first to apply ensemble learning to auto-tuning the input/output in high-performance computing, over-
2168-9253/23/$31.00 ©2023 IEEE DOI 10.1109/CLUSTER52292.2023.00027

<sup>∗</sup> Equal contribution.

<sup>§</sup> Corresponding Author.

<sup>1</sup>Code, data, and documents can be accessed at *https://github.com/zhangyuliu/OPRAEL/*

coming the limitations of single-algorithm approaches. (Sec. III);

- We present different prediction models for read and write performance, and use the PFI and SHAP methods to identify key performance impacting parameters. (Sec. IV-C);
- We experimentally confirm that ensemble learning significantly improves algorithmic performance, efficiency, and stability, resulting in better and more reliable I/O performance. (Sec. IV-D);

#### II. BACKGROUND AND MOTIVATION

Implementing efficient parallel I/O in HPC applications is a herculean task. It is influenced and limited by several factors, including the growing complexity of supercomputers, the shared nature of I/O subsystems, large and sparse search space, and administrator restrictions. These factors combine to make improving I/O performance a very challenging task. To our best knowledge, since Ying Chen first used auto-tuning techniques for HPC I/O auto-tuning in 1998 [20] [21] [22], various algorithms have been used for auto-tuning of HPC I/O parameters. Genetic Algorithm and Simulated Annealing were first applied to the field to search the entire parameter space systematically. However, they may waste too much time on configurations with inferior performance, resulting in long tuning times. Based on more profound understanding of I/O, researchers have focused on exploring rule-based algorithms [23] [24] to calculate the values of tuning parameters using initially readily available data such as file size. However, this approach is not flexible enough. With the development of machine learning techniques, regression models [25] [26] [27] and later reinforcement learning [28] [18] were also applied. The former implements prediction-based tuning to predict the performance of all configurations in the parameter space and select Top k to run. The latter performs policybased explorations in a given space. A common feature of these efforts is that they let the tuning algorithms work independently, relying on their own search strategies to search for the optimal configuration. This raises the problems of long tuning time, slow convergence rates, and a greater tendency to get stuck in local optima for long periods.

Considering the above problems, we expect using ensemble learning to share knowledge among multiple algorithms. This method offers two primary benefits. Firstly, it accelerates the search process and convergence of an algorithm by utilizing the superior results achieved by other algorithms. For instance, for a single algorithm, an example performance curve is presented in Fig. 1 (a). Once the algorithm discovers point A, it can locate the first peak after many iterations, depending on its search strategy. After reaching the first peak, it may be possible to escape from the local optima by leveraging its own strategies, explore point B, and gradually approach the actual peak. Generally, finding point B can require numerous iterations, but if another algorithm has already found it and informed the algorithm, it can perform additional exploration based on this point, accelerating the search process. Secondly, this method can yield superior performance results that are more stable. A single algorithm is unstable because it requires constant exploration to find a better configuration. In the process, it may encounter configurations with abysmal performance. The method, after integration, does not get configurations from a single algorithm but chooses the best one from several configurations generated by different algorithms, which essentially minimizes the impact of uncertainty in the exploration process. As shown in the Fig. 1 (b), algorithms A and B have different performance curves, and in each round there are two choices, A1 and B1, and the better one is chosen each round so that better and more stable results can be obtained than individual algorithms. Overall, ensemble learning improves each sub-algorithm and selects the best from the sub-algorithms to make the whole better.

![](_page_1_Figure_7.png)

Fig. 1. This figure shows our motivation with examples of how better configurations from other algorithms affect the search speed and performance of a certain algorithm (a) and the improvement of overall performance (b).

### III. AUTO-TUNING FRAMEWORK

We propose an ensemble learning-based auto-tuning framework to automatically determine the settings of I/O parameters, as shown in Fig. 2. The framework consists of two main parts: Part I trains a predictive model that is used for performance prediction during tuning. Model interpretability module is leveraged to obtain important parameter rankings that guide parameter space generation and answer which key parameters should be focused on during tuning. Part II is integrated with search algorithms that generate specific configurations and predicts the performance of each configuration using the predictive model. Based on the prediction results, the optimal configuration for the round is selected. Finally, the optimal configuration is evaluated by prediction or actual execution to obtain the result of this tuning round. The tuning process is terminated when the preset time or number of iterations is reached.

## *A. Prediction Model Based on Regression Analysis*

Modeling HPC application I/O performance using regression analysis focuses on modeling the relationship between I/O performance and IO stack parameters.

The first phase is to collect data for model training. Different sampling algorithms are compared to ensure that the data is well-distributed. With the dataset that has undergone feature selection and normalization, various regression models are trained to select the best one. Then, analytical methods, PFI and SHAP, conduct interpretability analysis on models and quantify the impact of parameters on performance with

![](_page_2_Figure_0.png)

Fig. 2. Overall Architecture of the Auto-Tuning Framework OPRAEL. In this framework, PART II's prediction model directly uses the model trained in PART I. Path I is based on the actual execution, and Path II uses the prediction results as the tuning results of the current iteration. Select one of the two for execution in each iteration.

values. Furthermore, single-factor experiments are conducted on parameters with high values to demonstrate their impact further. Finally, these crucial parameters will become part of the parameter space.

*1) Data Sampling:* First, selecting the sampling space and preprocessing the data before sampling is necessary. Selecting highly correlated parameters with the predicted target is decisive in improving the model's performance. This paper considers two types of features. One is related to I/O patterns, such as read or write, whether the accessed data space is contiguous or non-contiguous, and the size of the transmitted data [29]. Characteristics that describe the write pattern (the same as the read pattern) are shown in Table I. These features are extracted from log files generated by the monitoring tool Darshan [30]. Another is the tunable parameters from the I/O stack, shown in Table II.

| TABLE I |
| --- |
| CHARACTERISTICS RELATED TO WRITE PATTERN |

| Name | Description |  | Type |
| --- | --- | --- | --- |
| POSIX WRITES | Number of | write | Numerical |
|  | operations |  |  |
| POSIX CONSEC WRITES | Number in consec |  | Numerical |
|  | utive writing |  |  |
| POSIX SEQ WRITES | Number in sequen |  | Numerical |
|  | tial writing |  |  |
| POSIX SIZE WRITE {x y} | Write | data | Numerical |
|  | range[x,y] |  |  |
| POSIX BYTES WRITTEN | Total bytes of write |  | Numerical |
|  | Access |  |  |

Raw data usually performs at different magnitudes. For example, Romio CB Read ranges from 0 to 2, while

#### TABLE II PARAMETERS OF I/O STACK

| Name | Description | Type |
| --- | --- | --- |
| MPI Node | Number of compute nodes | Numerical |
| nprocs | Number of processes | Numerical |
| Block Size | Block size for a single process | Numerical |
| mode | I/O operations (read/write) | Categorical |
| strip count | Number of stripes | Numerical |
| strip size | Size of a single stripe (bytes) | Numerical |
| Romio CB Read | Enable collective buffer read or not | Categorical |
| Romio CB Write | Enable collective buffer write or not | Categorical |
| Romio DS Read | Enable data sieving for reading opera | Categorical |
|  | tions or not |  |
| Romio DS Write | Enable data sieving for writing opera | Categorical |
|  | tions or not |  |
| cb nodes | The maximum number of aggregators | Numerical |
|  | to be used |  |
| cb config list | Define how many aggregators can be | Numerical |
|  | used per node |  |

POSIX BYTES WRITTEN ranges from 106-109. Excessive range differences often affect the convergence speed and stability of the model. We performed a logarithmic transformation and normalization on these parameters to avoid the problem. For a vector X=(x1,x2,... ,xn), its log-transformed vector with a base of 10 is

$$X^{{}^{\prime}}=(log_{10}(x_{1}+1),log_{10}(x_{2}+1),...,log_{10}(x_{n}+1))\tag{1}$$

The increment prevents the result from going to infinity due to zero in the input data. The vector after normalization is

$$X^{\prime\prime}=(x_{1}/\sum_{i=1}^{n}x_{i},x_{2}/\sum_{i=1}^{n}x_{i},...,x_{n}/\sum_{i=1}^{n}x_{i})\tag{2}$$

It should be noted that this normalization is done on a row-by-row basis, with each row representing one run. The sum here can be the number of operations, the amount of transmitted data, and the number of files. It calculates the proportion of each operation to the total, thus measuring the importance of the operation in the current run. In addition, two most commonly used normalization methods, Min-max normalization and Z-score normalization, are also tried. Using the data processed by these two methods to train models, XGBoost still performs the best in all models and has almost the same error values as when using sum normalization. After that, LOG10 is added before the original feature name to construct a new one after a logarithmic transformation with a base of 10, and PERC is added after the original name after normalization.

Due to the large search space of I/O stack parameters, we choose to generate sample datasets as the training set to control the overhead. The sample datasets should be distributed as evenly as possible to enable better generalization and higher prediction accuracy of the performance models. We consider various methods of sampling a high-dimensional space in a balanced way, including Sobol sequence and Halton sequence in Quasi-Monte Carlo (QMC) method [31], Latin hypercube sampling (LHS) [32]. We also compare above methods with custom sampling methods of He Y et al. [33] and Tipu et al. [34]. They generate a configuration set by customizing the value interval of different parameters and then combining these values. The balance of collected data is evaluated through sample distribution experiments. Moreover, models are trained on the data, measuring data quality further with prediction results.

*2) Model Training:* Regression algorithms can help solve problems such as predicting continuous variables and analyzing the relationship between variables. We test some popular regression algorithms: linear regression [35], ensemble regression (XGBoost [36] and random forest [37]), KNN regression [38], and SVR [39]. In addition, several deep learning models are also tested, including MLP and CNN. The model, which is the best for modeling I/O performance, is selected by comparing the prediction error.

*3) Model Interpretive Analysis:* The prediction models for machine learning training are black-box. To find parameters that have a significant impact on model performance, PFI (Permutation feature importance) [40] and SHAP (SHapley Additive exPlanation) [41] [42] methods are used to analyze the model interpretively. PFI is a statistical method that can be used to evaluate the influence of input on output. Its main computational principle is selecting a parameter, re-predicting the model after randomly disrupting the parameter values, and then calculating the difference between results. The difference value is the importance score of the parameter. SHAP is a game theory approach to explain the black-box ML model, which mainly uses the idea of Shapley values to assign the contribution score of each parameter to different sample data, and the importance of one parameter is obtained by calculating its average contribution value among all samples. The contribution ranking can then identify the critical parameters [43]. In this paper, we use these two methods to analyze the read and write models, and conduct single-factor experiments to investigate the correlation between vital parameters and the performance.

#### *B. Parameter Search Based on Ensemble Learning*

Parameter search is an iterative process that may contain many rounds of tuning. A complete round of tuning consists of two processes. One is the generation of configurations. In our approach, each sub-search algorithm searches in parallel based on random seeds or optimal configurations in history (iterative data). Each generates configurations simultaneously and then selects the optimal one among them after voting integration, which is the optimal configuration generated in this round. The second is configuration measurement. Our framework provides two ways to evaluate the configuration, one is to use the prediction results directly, and the other is to inject the parameter configurations into the application and then actually run to get the performance results. Obtaining a performance result marks the end of this round of tuning. And then determine whether to continue tuning until the termination condition is reached.

*1) Prediction and Voting:* By combining the prediction model, a more efficient search approach is obtained by voting integration of Genetic Algorithm (GA), TPE, and Bayesian Optimization(BO). Considering the parallel execution of different sub-search algorithms, the Bagging algorithm is chosen for integration.

Initially, each sub-search algorithm generates random configurations simultaneously based on random seeds. Then a voting mechanism is used to select the best configuration in this round. We currently use the most straightforward way, where all base learners have the same weight. The working process of the voting mechanism is using the prediction model to predict the performance, then the configuration with the highest score is output as the final configuration of this round. Before entering the next round, the best configuration will be stored as iterative data, which will be selected as the seed for sub-searchers in the iteration process. The tuning ends when the set time or iterations is satisfied. The ensemble and votingbased search approach is shown in Algorithm 1.

## Algorithm 1: The ensemble and voting-based search algorithm

- Input: advisor list A collection of sub-search algorithms Output: next conf ig new parameter configuration
- 1 conf ig advisor list ←init advisor(advisor list);
- 2 pools ←ThreadPoolExecutor(advisor list.length);
- 3 foreach adv ∈ conf ig advisor list do
- 4 performance func ← performanceModel(adv.get suggestion());
- 5 pool.submit(performance func);
- 6 next conf ig ←get next config(pool.result());
- 7 return next conig ;

The working process of Algorithm 1 is as follows: (1) Take the integrated sub-search algorithm list as input, register and initialize the algorithms, and create a thread pool. (2) Traverse all the sub-searchers, obtain the parameter configurations generated by each searcher by calling the get suggestion() function, and then use it as the input of the prediction model. Finally, the model that predicts the bandwidth corresponding to each configuration is run to get prediction results. Note that although we optimize for bandwidth due to its importance in many applications, the idea of our approach is also applicable to other I/O metrics, such as the latency. (3) After obtaining the predicted results of all asynchronously executed searchers, the best configuration is returned as the output.

*2) Performance Measurement:* After obtaining the optimal configuration in each round, the corresponding bandwidth needs to be obtained as the endpoint for this round. There are two ways to achieve this, prediction and actual execution. The former directly uses the predicted results. For the latter, deploying the parameter configuration and executing the application is necessary. I/O tuner, a parameter injector, deploys tuned parameters to the application. It can both set parameters through the command line and dynamically set these parameters at the MPI-I/O ROMIO library and Lustre parallel file system based on the PMPI wrapper mechanism. PMPI implements the MPI standard. In PMPI's wrapper, users can insert functions before or after calling MPI functions. Here, we choose to wrap the function MPI File open (MPI Comm comm, const char *filename, int amode, MPI Info info, MPI File *fh), modify the info object before calling the original function, and then compile the function into a dynamic link library. By setting the environment variable LD PRELOAD, the compiled dynamic link library is loaded into the address space. When the MPI File open() is called, it will enter the wrapped function to complete the deployment of I/O stack parameters.

The process of obtaining actual performance results through execution can be time consuming and resource intensive. Alternatively, the use of predicted results can significantly speed up the search process. Therefore, the accuracy of the predictive model remains critical.

#### *C. System Implementation*

The proposed auto-tuning framework is implemented using the related API of Openbox [44]. Users need to define the parameters to be tuned and the performance evaluation function. It is also easy to customize additional sub-search algorithms for integration. During the tuning process, the configurations and corresponding results will be recorded, and finally, the optimal parameter configuration will be returned. The overall process is described in Algorithm 2.

The working process of Algorithm 2 is: (1) Initialize the search space according to the input parameter range, and initialize the timer and recorder. Call OPRAELOptimizer to register an ensemble search engine on the search space. (2) When the overhead time is within the search time limit, obtain the configuration of each iteration by calling the get suggestion()

#### Algorithm 2: The process of auto-tuning

| Input: conf igs : I/O stack parameters and range |
| --- |
| evaluate: performance evaluation function |
| runtime limit: time limit for optimization |
| Output: best conf ig the best parameter configuration |
| 1 conf ig space ←get space(conf ig); |
| 2 time ←start time(); |
| 3 history ←init history(); |
| 4 engine ←OPRAELOptimizer(conf ig space); |
| 5 while time < runtime limit do |
| 6 next conf ig ←engine.get suggestion(); |
| 7 performance ←evaluate(next conf ig); |
| engine.update(performance); 8 |
| 9 history.update(performance); |
| time.update(); 10 |
| 11 return history.best conf ig() ; |

function and then input it to the evaluation function to obtain the application performance. Update the search logger, search engine, and timer according to the feedback. (3) When the search time limit is reached, the optimal configuration in the logger is returned.

#### IV. EXPERIMENT

In this section, experiments will be conducted to verify the effectiveness of the OPRAEL framework. Specifically, we first evaluate the accuracy of the prediction model. To demonstrate the I/O performance boost enabled by OPRAEL, we design experiments to verify the improvement of the performance and efficiency of search algorithms, as well as the improvement in the quality of results.

## *A. Benchmarks*

We choose one I/O benchmark and two I/O kernels to evaluate our approach, with different settings representing different I/O patterns. I/O kernels are the I/O part extracted from the actual applications, which are simpler applications that issue the same I/O operations as full-scale HPC applications but can be executed much faster [24], [45]. The specific introduction is as follows:

- IOR [46] [47]: *InterleavedOrRandom*(IOR) is developed by Lawrence Livermore National Laboratory (LLNL). It is highly configurable and one of the most widely used I/O benchmarks. It contains different I/O interfaces and supports for parallel I/O libraries, such as HDF5, MPI-I/O, etc. Users can flexibly configure IOR to meet their testing needs.
- S3D-I/O [48]: This kernel is also commonly used in highperformance computing. It is developed for the combustion application S3D, which is mainly used to simulate the performance of S3D in different input and output modes. Different parallelism modes and I/O patterns can be selected, and the input configuration consists of the three-dimensional grid size. This paper uses the PnetCDF non-blocking I/O pattern of the kernel.
- BT-I/O [49]: BT-I/O is in NAS Parallel Benchmarks (NPB) used to evaluate parallel I/O performance, mainly

![](_page_5_Figure_0.png)

Fig. 3. Distribution of 50 data points based on Sobol, Halton, Custom, LHS sampling methods in high-dimensional space after t-SNE downscaling to twodimensional space.

used in large-scale parallel computing to evaluate BTassociated I/O performance, where BT is a program in NPB for solving equations in the form of block tridiagonal. Users can control the simulation's concurrent scale and data volume by setting the number of processes and input data size. This paper uses the PnetCDF nonblocking I/O pattern of this kernel.

## *B. System Setup*

All the experiments are run on the TianHe Exascale Prototype System deployed at the National Supercomputing Center in Tianjin, China. The system consists of 512 compute nodes. Each node has three proprietary CPUs called Matrix-2000+. The system memory is 98.3 TB, and the storage capacity is 1.4 PB in total. The software stack of the compute nodes primarily includes Ubuntu 20.04, MPICH 3.4.2 and PnetCDF 1.10.0.

# *C. Model Prediction*

We conducted experiments on the balance of dataset collection, the accuracy of model prediction, and the interpretability of the model.

*1) Sampling evaluation:* Sampling algorithms are mainly evaluated on the data balance and the effectiveness for model training.

The specific experimental setting is to generate data in the 8-dimensional space, where the range of each dimension is set as [(1,64), (1,1024), (1,64), (1,8), (0,2), (0,2), (0,2), (0,2)], respectively. Sampling algorithms, including Sobol sampling, Halton sampling, LHS, and custom sampling [33] [34], all generate 50 data points, using t-SNE [50] to reduce the dimension. t-SNE (t-distributed stochastic neighbor embedding) is a nonlinear algorithm commonly used in high-dimensional data dimensionality reduction and visualization. Fig. 3 shows that the data points generated by LHS are most evenly distributed.

Fig. 4 shows the model's accuracy trained by data from different sampling algorithms on IOR. XGBoost is chosen to build the models. The models all perform well in predicting the read performance, among which the data from LHS and custom sampling work best. The median absolute error of the model using LHS is 0.02. The accuracy of write performance is not as good as that of read performance. This might be

![](_page_5_Figure_10.png)

Fig. 4. Read (a) and write (b) bandwidth prediction results for XGBoost models trained on IOR data collected with Sobol, Halton, Custom, LHS sampling methods.

![](_page_5_Figure_12.png)

Fig. 5. Read (a) and write (b) bandwidth for XGBoost, Linear Regression, Random Forest Regression, k-nearest Neighbor Regression, Support Vector Regression, Multilayer Preceptron and Convolutional Neural Network models trained with IOR collected by LHS sampling for 70/30 split of train/test data.

caused by the active prefetching in multiple layers of the I/O stack for read operations. The regression model aims to fit the training data by optimizing the loss function. So when the loss function changes significantly in different samples, local overfitting may occur, affecting the generalization ability and prediction accuracy. Overall, models trained by datasets from LHS perform well for both read and write requests.

*2) Model Training:* About 40,000 samples related to the write operations and about 20,000 related to read operations are collected on IOR to train prediction models. Divide the dataset into a training set and a test set with a ratio of 7:3. Fig. 5 shows the absolute error.

As shown in Fig. 5, XGBoost and Random Forest regression's error values are minor. This may be because they are both based on ensemble learning. XGBoost is recommended because it is faster. The median absolute error is 0.03 on read prediction and 0.05 on write prediction, which is acceptable according to Isakov et al. [43]. It is difficult to reduce this error due to the external system environment [51].

*3) Interpretability Analysis:* PFI and SHAP perform interpretability analysis on models to find decisive parameters. The top six are shown in Fig. 6 and Fig. 7 for read and write requests, respectively. Larger values indicate more critical the parameters. The top six parameters selected by two methods are consistent for the read model, even if the order is inconsistent. For the write model, only one of the top six parameters differs; additionally, the first two most important parameters are consistent.

*4) Univariate Analysis:* In order to investigate the specific impact of critical parameters, univariate experiments are con-

![](_page_6_Figure_0.png)

Fig. 6. Parameter Importance Analysis Based on PFI and SHAP For Read Model. CB R: Romio CB Read. MPI Node: LOG10 MPI Node. FPerP: file per process. nprocs: LOG10 nprocs. CONSEC: POSIX CONSEC READS PERC. SEQ: POSIX SEQ READS PERC.

![](_page_6_Figure_2.png)

Fig. 7. Parameter Importance Analysis Based on PFI and SHAP For Write Model. Stripe C: LOG10 Strip Count. Stripe S: LOG10 Strip Size. SEQ: POSIX SEQ WRITES PERC. nprocs: LOG10 nprocs. blocksize: LOG10 Block Size. MPI Node: LOG10 MPI Node. CONSEC: POSIX CONSEC WRITES PERC.

ducted on the IOR dataset.

As shown in Fig. 8, we explore the impact of the number of processes on a single compute node. As the number of processes increases, the read performance under different file sizes shows a consistent trend. The number of processes significantly impacts read performance under various file sizes. For write performance, the variation is apparent only when the file size is 1G, while others tend to be flat.

The following study aims to observe the performance of a compute cluster by varying the number of compute nodes used for file reading and writing. Our results, shown in Fig. 9, indicate that increasing the number of compute nodes enhances read performance for files of almost all sizes. This improvement is particularly pronounced for larger files, as smaller files do not effectively utilize node resources. On the

![](_page_6_Figure_7.png)

Fig. 8. The scalability of read (a) and write (b) bandwidth of IOR for increasing processes on a single node at different file sizes.

![](_page_6_Figure_9.png)

Fig. 9. Scalability of read (a) and write (b) bandwidth of IOR with increasing number of compute nodes (32 processes on a single node) at different file sizes.

![](_page_6_Figure_11.png)

Fig. 10. Scalability of read (a) and write (b) bandwidth of IOR with increasing OSTs at different file sizes (8 compute nodes, 16 processes on a single node).

other hand, write performance shows significant improvement only when file size is 1G. This may be because parallel writing requires increased communication overhead between compute nodes as the number of nodes increases. Thus, further analysis is necessary to better understand write performance.

Based on the above analysis, it can be surmised that despite the increase in file size, there is no significant change in write performance as the number of processes and compute nodes increases. This result may be due to the fact that the system defaults the number of stripes to only one, resulting in contention between processes on the OSTs during parallel writes. Therefore, as shown in Figure 10, a thorough examination with different sets of OSTs is imperative.

For the read performance, except that the performance under the 1G size shows a first rise and then a decline, the overall performance drops in other cases. It indicates that increasing OSTs is not conducive to parallel reading. It may be because there is no mutual exclusion between read operations. Reading files on more OSTs increase the overhead of addressing and other operations. For write performance, except for the performance drop under 1G size, the performance of others increases first and then decreases. Moreover, as the size increases, the number of OSTs also increases to reach the peak. In summary, choosing fewer OSTs when considering read performance is appropriate, while write performance requires further consideration.

Considering the read and write performance comprehensively, it is still more inclined to choose more OSTs because write performance is more likely to become the I/O performance bottleneck from the perspective of the magnitude of read and write performance. In order to verify this idea, we set the number of OSTs from 1 to 32 to compare the performance

TABLE III I/O BANDWIDTH UNDER DIFFERENT OST QUANTITIES.(128 PROCESSES, 8 COMPUTING NODES, BLOCKSIZE=100M, TRANSFER SIZE=1M.)

| Quantity | Read | Write | Overall |
| --- | --- | --- | --- |
| 1 | 72369.44 | 2806.79 | 6193.32 |
| 2 | 47911.27 | 6005.07 | 10824.25 |
| 4 | 39012.81 | 6235.21 | 12644.12 |
| 8 | 42159.38 | 5374.17 | 11598.23 |
| 16 | 51350.25 | 4678.73 | 11151.33 |
| 32 | 33868.32 | 4641.04 | 10688.22 |

![](_page_7_Figure_2.png)

Fig. 11. Scatter plots of XGB-predicted values vs. measured values of write bandwidths for BT-I/O (left) and S3D-I/O (right).

variation, as shown in Table III.

The read and write bandwidth comes from the IOR's output, and Darshan collects the overall performance. The results show that when the read and write operations co-occur, improving write performance is more conducive to improving the overall application performance.

*5) Verification on S3D-I/O and BT-I/O:* This paper conducts verification experiments on S3D-I/O and BT-I/O, shown in Fig. 11.

We use SHAP to analyze the relationship between important parameters and performance. Fig. 12 shows results for the four parameters. A positive SHAP value means a positive impact on performance, and a negative value means a negative impact. It can be seen that setting the prohibition of data sieving of writing operations is beneficial to writing performance, while a large stripe size may not be conducive. The number of stripes

| TABLE IV |
| --- |
| THE TUNABLE PARAMETERS AND THEIR RANGES IN AUTO-TUNING |

| Parameter | Default | Benchmarks |  |  |
| --- | --- | --- | --- | --- |
|  |  | IOR | S3D-I/O | BT-I/O |
| stripe size | 1M | 1M-512M | 1M-1024M | 1M-1024M |
| stripe count | 1 | 1-32 | 1-64 | 1-64 |
| cb nodes | 1 | - | 1-64 | 1-64 |
| cb config list | 1 | - | 1-8 | 1-8 |
| romio cb read | ”automatic” | ”automatic”,”disable”,”enable” |  |  |
| romio cb write | ”automatic” | ”automatic”,”disable”,”enable” |  |  |
| romio ds read | ”automatic” | ”automatic”,”disable”,”enable” |  |  |
| romio ds write | ”automatic” | ”automatic”,”disable”,”enable” |  |  |

![](_page_7_Figure_10.png)

Fig. 12. SHAP is used to demonstrate feature dependency analysis on two different datasets. The top four panels show the S3D-I/O and the bottom four panels show the BT-I/O.

and nodes show a fluctuating state, requiring more specific analysis.

Based on the above analysis, we optimize S3D-I/O and BT-I/O under different input sizes by setting striping factor, romio ds write, cb nodes, and cb config list. Fig. 13 shows the comparison results. The performance after tuning has been significantly improved, especially when the file size is large. Among them, a performance acceleration of up to 10.2X is achieved on BT-I/O with an input size of 500 × 500 × 500. It has proved that the prediction model can not only be used for performance prediction but also interpreted to determine which parameters can potentially lead to better performance.

#### *D. Auto-tuning Results*

Considering the importance of parameters obtained from analysis and previous work [12] [52], we choose to tune the parameters in MPI-IO and the Lustre file system. Table IV shows the default values and tuning range of these parameters.

![](_page_8_Figure_0.png)

Fig. 13. Tuning results on S3D-I/O and BT-I/O. X-ticks of the form x-y-z represents the 3D grid size of the input data. The data for each dimension has been reduced by a hundred times, such as 1x1x1 represents 100x100x100.

![](_page_8_Figure_2.png)

Fig. 14. Tuning results for IOR with 200 MB block size under different processes based on execution(left) and prediction(right).

*1) Performance of* OPRAEL: To verify the improvement of I/O performance by OPRAEL, we compare it with the default setting and two tuning frameworks, Pyevolve [10] and Hyperopt [53]. Experiments are conducted under two measurement ways, including 30 minutes of actual execution and 10 minutes of prediction.

Fig. 14 shows the results under different number of process testing the IOR benchmark. OPRAEL performs best in both execution and prediction. As the number of process increases, the advantage of OPRAEL becomes more distinct in both scenarios. Moreover, the performance boost obtained from the prediction is lower than that of execution under all experimental conditions. It may be because although the model has relatively high prediction accuracy, they still fail to perfectly model the complete aspects of the real system, thus affecting the optimal parameters' convergence during the search process. Compared with the performance of the default setting, the speedup is up to 8.4X under 128 processes in execution. Comparing and analyzing the tuned parameters with the default parameters shows that more OSTs are selected than the default setting. More OSTs can achieve higher concurrency and, thus, better write performance.

Fig. 15 shows the results under different file sizes on IOR, S3D-I/O, and BT-I/O. OPRAEL has achieved the best performance in all cases. As the file size increases, the performance improvement of each approach compared to the default configuration has further increased, which indicates that the default configuration is unsuitable for handling large files and is not conducive to concurrent write operations. In the execution scenario, the highest speedup of 7.9X is achieved on BT/IO, while 7.2X is in the prediction scenario. The performance boost obtained by the model is less than that of actual execution in almost all cases. One unique set is S3D-I/O with 100x100x400, whose performance using the model is better than that of the actual execution.

Since reinforcement learning has achieved better results than heuristic search in dealing with some tasks with a large search space, we thus compare OPRAEL with the RL approach. The results on S3D-I/O and BT-I/O are shown in Fig. 16, searching for 30 minutes based on execution. OPRAEL obtains better results than RL for three input sizes on both kernels.

Fig. 17(a) shows the search efficiency of two approaches. The search efficiency of RL is worse than that of OPRAEL. Within the time interval, RL fails to identify better configurations while OPRAEL rapidly identifies a decent one and continuously refines it.

*2) Performance Improvements and Efficiency of Search Algorithms:* The experiments demonstrate the improvement in performance and search efficiency of algorithms before and after integration.

Fig. 17(b) compares the performance of sub-searchers and OPRAEL. OPRAEL performs better than other algorithms on both datasets. It proves the effectiveness of ensemble learning, which can achieve higher performance improvements than individual algorithms.

Fig. 18 shows the search efficiency of these four algorithms. Bayesian Optimization has performed the most iterations for single algorithms. Nonetheless, OPRAEL has reached the top, and the data points show a tendency to obtain higher performance. Therefore, using ensemble learning to combine basic search algorithms can improve the efficiency of exploring the parameter space.

In order to further explore the influence of ensemble learning on the search process of sub-search algorithms, the experiment is set within fixed iterations to compare the efficiency of algorithms before and after integration to highlight the impact of good configurations from other algorithms, as shown in Fig. 19. In order to more accurately observe the impact between configurations, we replaced the prediction model with actual execution, so the bandwidth here is the result of actual execution. For each sub search algorithm, the integrated algorithm performs better than before. This proves that it is valuable to share knowledge between different algorithms. They can be further explored based on better configurations of other algorithms, which are more likely to result in better configurations.

*3) Improvements to result stability and performance:* Based on the experimental results of the fixed rounds above, we plot the performance results of OPRAEL and pre-integration sub-algorithms, as shown in Fig. 20. In terms of performance and stability of the results, OPRAEL performs much better than other sub-algorithms, which confirms the effectiveness of ensemble learning.

![](_page_9_Figure_0.png)

Fig. 15. Tuning results for IOR, S3D-I/O, BT-I/O with various file sizes based on execution(30 min) and prediction(10 min).

![](_page_9_Figure_2.png)

Fig. 16. Performance results of OPRAEL and RL. The data for each dimension has been reduced by a hundred times, such as 2x2x2=200x200x200.

![](_page_9_Figure_4.png)

Fig. 17. (a) Comparison of search efficiency between RL and OPRAEL. (b) Performance comparison of sub-search algorithms and OPRAEL.

#### *E. Tuning cost*

The overhead of employing OPRAEL can be unraveled as follows:

a. Offline training and model interpretive analysis (Sec. III-A). Regarding time cost, model training and interpretation analysis can be completed in a few seconds to a dozen seconds. In our experiment, for IOR with more than 30,000 pieces of data, it only takes a dozen seconds to complete the training. Interpretation analysis can be completed in a few seconds, such as in IOR, which takes about 2 seconds and 5 seconds to complete the SHAP and PFI analysis, respectively. Moreover, these two parts are reusable unless users want to add new training data to retrain the model. In terms of resources used, model training and analysis can be completed offline on an available node. This will not cause interference to other running jobs.

b. Parameter search and online usage (Sec. III-B). The time for a single round of parameter search is very short, such as milliseconds in IOR. Therefore, predictive tuning is fast as it only needs to put the obtained configuration into the model for prediction. In contrast, execution-based tuning requires the actual execution of applications to determine the optimal performance for the current round, so it depends significantly on the application scale. The total search time or the number of iterations can be customized by users. As for the resources used in tuning, they mainly include compute nodes, network, and back-end storage resources. Prediction-based tuning only needs a single compute node, while execution-based tuning requires all the above resources. For the latter, the resources are specified by users or by default. Regarding the impact on the overall performance of the system, prediction-based tuning can be completed on a single node which is used exclusively on Tianhe, and will not affect other applications; in execution-based tuning, Tianhe schedules it as regular jobs, this mechanism ensures that they have no noticeable impact on other programs.

#### V. RELATED WORK

Autotuning the performance of the I/O software stack is highly challenging. A large number of parameters from different layers generate an ample parameter space. As far

![](_page_10_Figure_0.png)

Fig. 18. The figure shows the number of iterations and the obtained performance of the four comparison methods in the same time (30 min).

![](_page_10_Figure_2.png)

Fig. 19. Performance comparison of search algorithms before and after integration. The performance results of each round are obtained through actual execution.

![](_page_10_Figure_4.png)

Fig. 20. Performance comparison of results before and after integration. The results of three sub search algorithms are obtained by running each algorithm separately. And the performance results of each round are obtained through actual execution.

as we know, since Ying Chen's team first used auto-tuning methods for auto-tuning HPC I/O parameters in 1998 [20] [21] [22], various methods have been used for tuning on different systems and scales. Genetic Algorithm [20] [12] [13] and Simulated Annealing [22] [54] have been used to solve this problem. However, they have a lot of overhead and waste time on bad performance configurations. Bagbaba [27] ˘ [55] built a random forest model to predict all configurations in the parameter space and selected the best-performing top K for actual execution based on the prediction results. This approach uses predicted results instead of actual execution to reduce optimization costs greatly, but its performance heavily depends on the accuracy of models. Behzad et al. [24] develop a pattern-driven autotuning framework. They use applications' dimensions, distributions, and sizes to define the pattern and get the configuration with the same pattern. Reinforcement learning is a prevalent technique in deep learning and is also employed for parameter optimization in parallel file systems [17] [18].

#### VI. DISCUSSION AND CONCLUSION

This paper applies ensemble learning to HPC I/O autotuning for the first time, solving problems in individual algorithms by sharing knowledge. Our approach includes developing prediction models for read and write performance, performing interpretability analysis of the models, quantifying the effect of parameters on performance, and designing experiments to explore the variation of performance with important parameters. We tested OPRAEL on Tianhe-II with one I/O benchmark(IOR) and two I/O kernels(S3D-I/O, BT-I/O). Our experimental results demonstrate that our approach improves performance by up to 8.4X over the default configuration and outperforms Pyevolve [10] and Hyperopt [53] in all scenarios. We also found that ensemble learning improves search algorithms' performance and efficiency, improving the results' performance and stability. The framework currently integrates three algorithms and can easily incorporate new algorithms to allow for greater learning opportunities. However, our experiments show that the system environment greatly impacts performance, which reduces the results' stability. In future work, we will aim to minimize the impact of the system environment on performance, such as designing strategies to select specific storage devices to reduce the impact of device load on performance. In addition, we will also explore tuning on real applications in system environments. It will be a challenging and valuable job.

## ACKNOWLEDGMENT

We thank the CLUSTER anonymous reviewers for their constructive feedback. This work was supported in part by the National Natural Science Foundation of China (NSFC) under grant agreements 61972314, 62372373, the Shaanxi International Science and Technology Cooperation Program (2023- GHZD-04), the Shaanxi Province "Engineers + Scientists" Team Building Program (2023KXJ-055), Northwest University's 2023 Graduate Innovation Program (CX2023190).

## REFERENCES

- [1] Z. Zhu, S. Neuwirth, and T. Lippert, "A comprehensive i/o knowledge cycle for modular and automated hpc workload analysis," in *2022 IEEE International Conference on Cluster Computing (CLUSTER)*. IEEE, 2022, pp. 581–588.
- [2] J. Han, D. Kim, and H. Eom, "Improving the performance of lustre file system in hpc environments," in *2016 IEEE 1st International Workshops on Foundations and Applications of Self* Systems (FAS* W)*. IEEE, 2016, pp. 84–89.
- [3] S. Neuwirth and A. K. Paul, "Parallel i/o evaluation techniques and emerging hpc workloads: A perspective," in *2021 IEEE International Conference on Cluster Computing (CLUSTER)*. IEEE, 2021, pp. 671– 679.
- [4] J. L. Bez, H. Tang, B. Xie, D. Williams-Young, R. Latham, R. Ross, S. Oral, and S. Byna, "I/o bottleneck detection and tuning: Connecting the dots using interactive log analysis," in *2021 IEEE/ACM Sixth International Parallel Data Systems Workshop (PDSW)*. IEEE, 2021, pp. 15–22.
- [5] H. Tang, B. Xie, S. Byna, P. Carns, Q. Koziol, S. Kannan, J. Lofstead, and S. Oral, "Sctuner: An autotuner addressing dynamic i/o needs on supercomputer i/o subsystems," in *2021 IEEE/ACM Sixth International Parallel Data Systems Workshop (PDSW)*. IEEE, 2021, pp. 29–34.
- [6] A. Bagbaba and X. Wang, "Improving the mpi-io performance of ˘ applications with genetic algorithm based auto-tuning," in *2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)*. IEEE, 2021, pp. 798–805.
- [7] "The hdf group hierarchical data format, version 5." [Online]. Available: https://www.hdfgroup.org/solutions/hdf5/
- [8] J. Li, W.-k. Liao, A. Choudhary, R. Ross, R. Thakur, W. Gropp, R. Latham, A. Siegel, B. Gallagher, and M. Zingale, "Parallel netcdf: A high-performance scientific i/o interface," in *Proceedings of the 2003 ACM/IEEE conference on Supercomputing*, 2003, p. 39.
- [9] R. Thakur, E. Lusk, and W. Gropp, "Users guide for romio: A high-performance, portable mpi-io implementation," Argonne National Lab.(ANL), Argonne, IL (United States), Tech. Rep., 1997.
- [10] B. Behzad, S. Byna, and M. Snir, "Optimizing i/o performance of hpc applications with autotuning," *ACM Transactions on Parallel Computing (TOPC)*, vol. 5, no. 4, pp. 1–27, 2019.
- [11] M. Seiz, P. Offenhauser, S. Andersson, J. H ¨ otzer, H. Hierl, B. Nestler, ¨ and M. Resch, "Lustre i/o performance investigations on hazel hen: experiments and heuristics," *The Journal of Supercomputing*, pp. 1–29, 2021.
- [12] B. Behzad, H. V. T. Luu, J. Huchette, S. Byna, R. Aydt, Q. Koziol, and M. Snir, "Taming parallel i/o complexity with auto-tuning," in *Proceedings of the international conference on high performance computing, networking, storage and analysis*, 2013, pp. 1–12.
- [13] B. Behzad, J. Huchette, H. V. T. Luu, R. Aydt, S. Byna, Y. Yao, and Q. Koziol, "A framework for auto-tuning hdf5 applications," in *Proceedings of the 22nd international symposium on High-performance parallel and distributed computing*, 2013, pp. 127–128.
- [14] B. Behzad, S. Byna, S. M. Wild, M. Prabhat, and M. Snir, "Improving parallel i/o autotuning with performance modeling," in *Proceedings of the 23rd international symposium on High-performance parallel and distributed computing*, 2014, pp. 253–256.
- [15] M. Agarwal, D. Singhvi, P. Malakar, and S. Byna, "Active learningbased automatic tuning and prediction of parallel i/o performance," in *2019 IEEE/ACM Fourth International Parallel Data Systems Workshop (PDSW)*. IEEE, 2019, pp. 20–29.
- [16] M. Agarwal, P. Jain, D. Singhvi, and P. Malakar, "Execution-and prediction-based auto-tuning of parallel read and write parameters," in *2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)*. IEEE, 2021, pp. 587–594.
- [17] Z. Wentao, W. Lu, and C. Yaodong, "Performance optimization of lustre file system based on reinforcement learning," *Journal of Computer Research and Development*, 2019.
- [18] H. Zhu, D. Scheinert, L. Thamsen, K. Gontarska, and O. Kao, "Magpie: Automatically tuning static parameters for distributed file systems using deep reinforcement learning," in *2022 IEEE International Conference on Cloud Engineering (IC2E)*. IEEE, 2022, pp. 150–159.

- [19] S. Robert, S. Zertal, and G. Goret, "Auto-tuning of io accelerators using black-box optimization," in *2019 International Conference on High Performance Computing & Simulation (HPCS)*. IEEE, 2019, pp. 1022–1027.
- [20] Y. Chen, M. Winslett, Y. Cho, and S. Kuo, "Automatic parallel i/o performance optimization using genetic algorithms," in *Proceedings. The Seventh International Symposium on High Performance Distributed Computing (Cat. No. 98TB100244)*. IEEE, 1998, pp. 155–162.
- [21] Y. Chen and M. Winslett, "Speeding up automatic parallel i/o performance optimization in panda," in *High Performance Computing Systems and Applications*. Springer, 1998, pp. 149–162.
- [22] Y. Chen, M. Winslett, Y. Cho, and S. Kuo, "Automatic parallel i/o performance optimization in panda," in *Proceedings of the tenth annual ACM symposium on Parallel algorithms and architectures*, 1998, pp. 108–118.
- [23] M. Chaarawi and E. Gabriel, "Automatically selecting the number of aggregators for collective i/o operations," in *2011 IEEE International Conference on Cluster Computing*. IEEE, 2011, pp. 428–437.
- [24] B. Behzad, S. Byna, and M. Snir, "Pattern-driven parallel i/o tuning," in *Proceedings of the 10th Parallel Data Storage Workshop*, 2015, pp. 43–48.
- [25] S. Kumar, A. Saha, V. Vishwanath, P. Carns, J. A. Schmidt, G. Scorzelli, H. Kolla, R. Grout, R. Latham, R. Ross *et al.*, "Characterization and modeling of pidx parallel i/o for performance optimization," in *Proceedings of the international conference on high performance computing, networking, storage and analysis*, 2013, pp. 1–12.
- [26] B. Behzad, S. Byna, S. M. Wild, M. Snir *et al.*, "Dynamic model-driven parallel i/o performance tuning," in *2015 IEEE International Conference on Cluster Computing*. IEEE, 2015, pp. 184–193.
- [27] A. Bagbaba, "Improving collective i/o performance with machine learn- ˘ ing supported auto-tuning," in *2020 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)*. IEEE, 2020, pp. 814–821.
- [28] Y. Li, K. Chang, O. Bel, E. L. Miller, and D. D. Long, "Capes: Unsupervised storage performance tuning using neural network-based deep reinforcement learning," in *Proceedings of the international conference for high performance computing, networking, storage and analysis*, 2017, pp. 1–14.
- [29] X. Limin and H. Zhisheng, "Review of i/o performance optimization technology for big data storage system," *Big Data Research (BDR)*, vol. 3, no. 6, p. 2017062, 2017.
- [30] S. Snyder, P. Carns, K. Harms, R. Ross, G. K. Lockwood, and N. J. Wright, "Modular hpc i/o characterization with darshan," in *2016 5th workshop on extreme-scale programming tools (ESPT)*. IEEE, 2016, pp. 9–17.
- [31] N. A. Mohammed, "Comparing halton and sobol sequences in integral evaluation," *Zanco Journal of Pure and Applied Sciences*, vol. 31, no. 1, pp. 32–39, 2019.
- [32] M. D. McKay, R. J. Beckman, and W. J. Conover, "A comparison of three methods for selecting values of input variables in the analysis of output from a computer code," *Technometrics*, vol. 42, no. 1, pp. 55–61, 2000.
- [33] Y. He, D. Dai, and F. S. Bao, "Modeling hpc storage performance using long short-term memory networks," in *2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)*. IEEE, 2019, pp. 1107–1114.
- [34] A. J. S. Tipu, P. O. Conbhu ´ ´ı, and E. Howley, "Applying neural networks to predict hpc-i/o bandwidth over seismic data on lustre file system for exseisdat," *Cluster Computing*, vol. 25, no. 4, pp. 2661–2682, 2022.
- [35] X. Yan and X. Su, *Linear regression analysis: theory and computing*. world scientific, 2009.
- [36] T. Chen and C. Guestrin, "Xgboost: A scalable tree boosting system," in *Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining*, 2016, pp. 785–794.
- [37] T. K. Ho, "Random decision forests," in *Proceedings of 3rd international conference on document analysis and recognition*, vol. 1. IEEE, 1995, pp. 278–282.
- [38] O. Kramer and O. Kramer, "K-nearest neighbors," *Dimensionality reduction with unsupervised nearest neighbors*, pp. 13–23, 2013.
- [39] D. A. Pisner and D. M. Schnyer, "Support vector machine," in *Machine learning*. Elsevier, 2020, pp. 101–121.

- [40] A. Altmann, L. Tolos¸i, O. Sander, and T. Lengauer, "Permutation importance: a corrected feature importance measure," *Bioinformatics*, vol. 26, no. 10, pp. 1340–1347, 2010.
- [41] S. M. Lundberg and S.-I. Lee, "A unified approach to interpreting model predictions," *Advances in neural information processing systems*, vol. 30, 2017.
- [42] S. M. Lundberg, G. Erion, H. Chen, A. DeGrave, J. M. Prutkin, B. Nair, R. Katz, J. Himmelfarb, N. Bansal, and S.-I. Lee, "From local explanations to global understanding with explainable ai for trees," *Nature machine intelligence*, vol. 2, no. 1, pp. 56–67, 2020.
- [43] M. Isakov, E. Del Rosario, S. Madireddy, P. Balaprakash, P. Carns, R. B. Ross, and M. A. Kinsy, "Hpc i/o throughput bottleneck analysis with explainable local models," in *SC20: International Conference for High Performance Computing, Networking, Storage and Analysis*. IEEE, 2020, pp. 1–13.
- [44] Y. Li, Y. Shen, W. Zhang, Y. Chen, H. Jiang, M. Liu, J. Jiang, J. Gao, W. Wu, Z. Yang *et al.*, "Openbox: A generalized black-box optimization service," in *Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining*, 2021, pp. 3209–3219.
- [45] B. Behzad, H.-V. Dang, F. Hariri, W. Zhang, and M. Snir, "Automatic generation of i/o kernels for hpc applications," in *2014 9th Parallel Data Storage Workshop*. IEEE, 2014, pp. 31–36.
- [46] LLNL, "Ior," 2015. [Online]. Available: https://github.com/hpc/ior
- [47] "Ior." [Online]. Available: https://buildmedia.readthedocs.org/media/pdf/ ior/latest/ior.pdf
- [48] "S3d-io." [Online]. Available: https://github.com/wkliao/S3D-IO/

- [49] P. Wong and R. Der Wijngaart, "Nas parallel benchmarks i/o version 2.4," *NASA Ames Research Center, Moffet Field, CA, Tech. Rep. NAS-03-002*, p. 91, 2003.
- [50] L. Van der Maaten and G. Hinton, "Visualizing data using t-sne." *Journal of machine learning research*, vol. 9, no. 11, 2008.
- [51] G. K. Lockwood, W. Yoo, S. Byna, N. J. Wright, S. Snyder, K. Harms, Z. Nault, and P. Carns, "Umami: a recipe for generating meaningful metrics through holistic i/o performance analysis," in *Proceedings of the 2nd Joint International Workshop on Parallel Data Storage & Data Intensive Scalable Computing Systems*, 2017, pp. 55–60.
- [52] M. Agarwal, D. Singhvi, P. Malakar, and S. Byna, "Active learningbased automatic tuning and prediction of parallel i/o performance," in *2019 IEEE/ACM Fourth International Parallel Data Systems Workshop (PDSW)*. IEEE, 2019, pp. 20–29.
- [53] J. Bergstra, D. Yamins, and D. Cox, "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures," in *International conference on machine learning*. PMLR, 2013, pp. 115–123.
- [54] Y. Chen and M. Winslett, "Automated tuning of parallel i/o systems: An approach to portable i/o performance for scientific applications," *IEEE Transactions on Software Engineering*, vol. 26, no. 4, pp. 362–383, 2000.
- [55] A. Bagbaba, X. Wang, C. Niethammer, and J. Gracia, "Improving the ˘ i/o performance of applications with predictive modeling based autotuning," in *2021 International Conference on Engineering and Emerging Technologies (ICEET)*. IEEE, 2021, pp. 1–6.

